{"metadata":{"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":43183,"sourceType":"datasetVersion","datasetId":31879}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NLP Project - Social Media Text Classification","metadata":{}},{"cell_type":"markdown","source":"## Project Overview\nThis project involves classifying social media texts into 'Relevant' and 'Not Relevant' categories using Natural Language Processing (NLP) and Machine Learning techniques.\n## Projeye Genel Bakış\nBu proje, sosyal medya metinlerinin Doğal Dil İşleme (NLP) ve Makine Öğrenimi tekniklerini kullanarak 'İlgili' ve 'İlgili Değil' kategorilerine göre sınıflandırılmasını içermektedir.\n","metadata":{}},{"cell_type":"markdown","source":"## Data Loading and Preparation","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport string\nimport nltk\nimport re  \n\nfrom nltk.corpus import stopwords, wordnet\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\n\n# NLTK kaynaklarını indirme\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('averaged_perceptron_tagger')\nnltk.download('wordnet')","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:39:47.203092Z","iopub.execute_input":"2024-01-13T10:39:47.203539Z","iopub.status.idle":"2024-01-13T10:39:47.216617Z","shell.execute_reply.started":"2024-01-13T10:39:47.203505Z","shell.execute_reply":"2024-01-13T10:39:47.215202Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/nlp-starter-test/socialmedia_relevant_cols.csv',encoding='latin1')","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:39:47.224351Z","iopub.execute_input":"2024-01-13T10:39:47.225232Z","iopub.status.idle":"2024-01-13T10:39:47.256715Z","shell.execute_reply.started":"2024-01-13T10:39:47.225195Z","shell.execute_reply":"2024-01-13T10:39:47.255605Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"df.head(8)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:39:47.258741Z","iopub.execute_input":"2024-01-13T10:39:47.259196Z","iopub.status.idle":"2024-01-13T10:39:47.272536Z","shell.execute_reply.started":"2024-01-13T10:39:47.259156Z","shell.execute_reply":"2024-01-13T10:39:47.271134Z"},"trusted":true},"execution_count":85,"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"                                                text choose_one  class_label\n0                 Just happened a terrible car crash   Relevant            1\n1  Our Deeds are the Reason of this #earthquake M...   Relevant            1\n2  Heard about #earthquake is different cities, s...   Relevant            1\n3  there is a forest fire at spot pond, geese are...   Relevant            1\n4             Forest fire near La Ronge Sask. Canada   Relevant            1\n5  All residents asked to 'shelter in place' are ...   Relevant            1\n6  13,000 people receive #wildfires evacuation or...   Relevant            1\n7  Just got sent this photo from Ruby #Alaska as ...   Relevant            1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>choose_one</th>\n      <th>class_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Just happened a terrible car crash</td>\n      <td>Relevant</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>Relevant</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Heard about #earthquake is different cities, s...</td>\n      <td>Relevant</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>there is a forest fire at spot pond, geese are...</td>\n      <td>Relevant</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>Relevant</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>Relevant</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>Relevant</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>Relevant</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = df.drop(\"choose_one\",axis=1) ","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:39:47.275262Z","iopub.execute_input":"2024-01-13T10:39:47.275761Z","iopub.status.idle":"2024-01-13T10:39:47.282896Z","shell.execute_reply.started":"2024-01-13T10:39:47.275718Z","shell.execute_reply":"2024-01-13T10:39:47.282007Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"markdown","source":"## Data Cleaning and Preprocessing","metadata":{}},{"cell_type":"code","source":"# Metni küçük harfe dönüştürme\ndf['text'] = df['text'].str.lower() \n\ndf['text'] = df['text'].str.replace(r'https?://\\S+|www\\.\\S+', '', regex=True)\n\n# HTML taglarını kaldırma\ndf['text'] = df['text'].str.replace(r'<.*?>', '', regex=True)\n\n# Noktalama ve numaraları kaldırma\ndf['text'] = df['text'].str.replace(r'[^a-zA-Z\\s]', '', regex=True)\n\n# Fazladan boşlukları kaldırma\ndf['text'] = df['text'].str.replace(r'\\s+', ' ', regex=True).str.strip()","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:39:47.284566Z","iopub.execute_input":"2024-01-13T10:39:47.285403Z","iopub.status.idle":"2024-01-13T10:39:47.527309Z","shell.execute_reply.started":"2024-01-13T10:39:47.285372Z","shell.execute_reply":"2024-01-13T10:39:47.526031Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"x = df['text']\ny = df['class_label']","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:39:47.528584Z","iopub.execute_input":"2024-01-13T10:39:47.528913Z","iopub.status.idle":"2024-01-13T10:39:47.534730Z","shell.execute_reply.started":"2024-01-13T10:39:47.528884Z","shell.execute_reply":"2024-01-13T10:39:47.533483Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"x[60]","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:39:47.538102Z","iopub.execute_input":"2024-01-13T10:39:47.539024Z","iopub.status.idle":"2024-01-13T10:39:47.549123Z","shell.execute_reply.started":"2024-01-13T10:39:47.538981Z","shell.execute_reply":"2024-01-13T10:39:47.547849Z"},"trusted":true},"execution_count":89,"outputs":[{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"'psa i m splitting my personalities techies follow ablazeco burners follow ablaze'"},"metadata":{}}]},{"cell_type":"code","source":"x[99]","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:39:47.551421Z","iopub.execute_input":"2024-01-13T10:39:47.551884Z","iopub.status.idle":"2024-01-13T10:39:47.560000Z","shell.execute_reply.started":"2024-01-13T10:39:47.551853Z","shell.execute_reply":"2024-01-13T10:39:47.558718Z"},"trusted":true},"execution_count":90,"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"'accident cleared in paturnpike on patp eb between pa and cranberry slow back to traffic'"},"metadata":{}}]},{"cell_type":"code","source":"# İngilizce stop words listesi\nstop_words = set(stopwords.words('english'))\n\n# Vektorize Etme ve stop words çıkartma\nvect = CountVectorizer(ngram_range=(1,2),stop_words='english')\n\nx=vect.fit_transform(x)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:39:47.561513Z","iopub.execute_input":"2024-01-13T10:39:47.562000Z","iopub.status.idle":"2024-01-13T10:39:48.194328Z","shell.execute_reply.started":"2024-01-13T10:39:47.561970Z","shell.execute_reply":"2024-01-13T10:39:48.193308Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"x","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:39:48.195617Z","iopub.execute_input":"2024-01-13T10:39:48.196117Z","iopub.status.idle":"2024-01-13T10:39:48.202936Z","shell.execute_reply.started":"2024-01-13T10:39:48.196087Z","shell.execute_reply":"2024-01-13T10:39:48.201900Z"},"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"<10876x80465 sparse matrix of type '<class 'numpy.int64'>'\n\twith 171400 stored elements in Compressed Sparse Row format>"},"metadata":{}}]},{"cell_type":"code","source":"# Splitting the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n\n# Initializing the RandomForestClassifier\nrf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Training the classifier\nrf_classifier.fit(X_train, y_train)\n\n# Predicting on the test set\ny_pred = rf_classifier.predict(X_test)\n\n# Evaluating the model\naccuracy = accuracy_score(y_test, y_pred)\nclassification_report_results = classification_report(y_test, y_pred)\n\nprint(\"Accuracy: \",accuracy)\nprint(\"Clasification Report: \",classification_report_results)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:39:48.205065Z","iopub.execute_input":"2024-01-13T10:39:48.205417Z","iopub.status.idle":"2024-01-13T10:41:57.216894Z","shell.execute_reply.started":"2024-01-13T10:39:48.205387Z","shell.execute_reply":"2024-01-13T10:41:57.215481Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stdout","text":"Accuracy:  0.8001838798651547\nClasification Report:                precision    recall  f1-score   support\n\n           0       0.78      0.90      0.84      1857\n           1       0.84      0.67      0.74      1401\n           2       0.00      0.00      0.00         5\n\n    accuracy                           0.80      3263\n   macro avg       0.54      0.52      0.53      3263\nweighted avg       0.81      0.80      0.80      3263\n\n","output_type":"stream"}]}]}